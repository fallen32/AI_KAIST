{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import metrics\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "from PIL import Image\n",
    "\n",
    "import torch # pytorch의 tensor와 그와 관련된 기본 연산 등을 지원\n",
    "import torch.nn as nn # 여러 딥러닝 layer와 loss, 함수 등을 클래스 형태로 지원\n",
    "import torch.nn.functional as F # 여러 loss, 함수 등을 function 형태로 지원\n",
    "import torch.optim as optim # 여러 optimizer를 지원\n",
    "import torchvision.models as models\n",
    "\n",
    "dev = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CosFace\n",
    "\n",
    "![Architecture](img/Cosface.PNG)\n",
    "\n",
    "ArcFace와 비슷한 모델 중 하나로 CosFace라는 모델이 있습니다. 위 Loss function은 CosFace의 loss function에 해당합니다. 위 loss function을 참고하여 아래의 ??? 부분을 채워주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosMarginProduct(nn.Module):\n",
    "    '''\n",
    "    목적 : Cosface 의 last fc layer의 구현\n",
    "    \n",
    "    인자 :\n",
    "    in_features : feature의 dimension\n",
    "    out_features : class 개수\n",
    "    '''\n",
    "    def __init__(self, in_features, out_features, s=30.0, m=0.1):\n",
    "        super(CosMarginProduct, self).__init__()        \n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        \n",
    "        # fc의 parameter 만들기 : (in_features x out_features)의 크기를 갖는 FloatTensor로 만들 것\n",
    "        self.weight = nn.Parameter(torch.zeros([out_features, in_features], dtype=torch.float32)).to(dev)\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        '''\n",
    "        Step 1. cos(theta)-m 계산하기\n",
    "        '''\n",
    "\n",
    "        # cos_theta = (x / ||x||) * (w * ||w||) 를 이용해 cosine_theta 구하기\n",
    "        # 어느 dimension을 기준으로 normalization을 해서 torch.mm에 넘겨줘야 할까요?\n",
    "        cos = torch.mm(F.normalize(input, dim=1), F.normalize(self.weight, dim=1))\n",
    "        \n",
    "        # cos_theta - m 구하기\n",
    "        cos_m = cos - self.m\n",
    "        \n",
    "        '''\n",
    "        Step 2. cos(theta)-m 에서 dim=1에 기준으로 y_i에 해당하는 부분만 남기고 나머지는 cos(theta)로 되돌리기 \n",
    "        '''\n",
    "        one_hot = torch.zeros(cos.size()).to(dev)\n",
    "        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n",
    "        output = (one_hot * cos_m) + (torch.abs(one_hot - 1) * cos)\n",
    "        \n",
    "        '''\n",
    "        Step 3. 최종 output 계산하기\n",
    "        '''\n",
    "        output *= self.s\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SphereFace\n",
    "\n",
    "![Architecture](img/Sphereface.PNG)\n",
    "\n",
    "ArcFace와 비슷한 모델 중 하나로 SphereFace 모델이 있습니다. 위 Loss function은 SphereFace의 loss function에 해당합니다. 위 loss function을 참고하여 아래의 ??? 부분을 채워주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SphereMarginProduct(nn.Module):\n",
    "    '''\n",
    "    목적 : Sphereface의 last fc layer의 구현\n",
    "    \n",
    "    인자 :\n",
    "    in_features : feature의 dimension\n",
    "    out_features : class 개수\n",
    "    '''\n",
    "    def __init__(self, in_features, out_features, m=4):\n",
    "        super(SphereMarginProduct, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.m = m\n",
    "        \n",
    "        # fc의 parameter 만들기 : (out_features x in_features)의 크기를 갖는 FloatTensor로 만들 것\n",
    "        self.weight = nn.Parameter(torch.zeros([out_features, in_features], dtype=torch.float32)).to(dev)\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        '''\n",
    "        Step 1. cos(m * theta) 계산하기\n",
    "        '''\n",
    "\n",
    "        # cos_theta = (x / ||x||) * (w * ||w||) 를 이용해 cosine_theta 구하기\n",
    "        # 어느 dimension을 기준으로 normalization을 해서 F.linear에 넘겨줘야 할까요?\n",
    "        cos = F.linear(F.normalize(input, dim=1), F.normalize(self.weight, dim=1))\n",
    "        \n",
    "        # cos(m * theta) 구하기. 논문에서 m=4로 제시하고 있으므로 m=4 일 경우에 대해서만 계산합니다.\n",
    "        # 효율성을 위해 arccos 등의 다른 연산 없이 위에서 얻은 cos만을 사용해 계산합니다.\n",
    "        cos_m = 8.0 * cos**4 - 8.0 * cos**2 + 1     # cos(2x) = 2*cos(x)**2 - 1\n",
    "        \n",
    "        '''\n",
    "        Step 2. cos(m * theta) 에서 dim=1에 기준으로 y_i에 해당하는 부분만 남기고 나머지는 cos(theta)로 되돌리기 \n",
    "        '''\n",
    "        one_hot = torch.zeros(cos.size()).to(dev)\n",
    "        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n",
    "        output = (one_hot * cos_m) + (torch.abs(one_hot - 1) * cos)\n",
    "        \n",
    "        '''\n",
    "        Step 3. 최종 output 계산하기\n",
    "        '''\n",
    "        x_norm = torch.norm(input)\n",
    "        output *= x_norm\n",
    "        return output\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backbone network\n",
    "\n",
    "ResNet-101을 이용하여 Backbone network를 구현합니다. 아래 코드의 ??? 부분을 채워주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureNet_101(nn.Module):\n",
    "    def __init__(self, dim_feature):\n",
    "        super(FeatureNet_101, self).__init__()\n",
    "        resnet = models.resnet101(pretrained=False)\n",
    "\n",
    "        # resnet-101의 마지막 Conv layer block 까지 남기고 그 뒷부분은 잘라냅니다.\n",
    "        # resnet-101 의 구조를 print해서 어디를 잘라야할 지 알 수 있습니다.\n",
    "        self.backbone = nn.Sequential(* list(resnet.children())[:-1])\n",
    "        \n",
    "        # 마지막 Conv layer block 부분 이후로 붙는 layer들입니다.\n",
    "        # resnet-101 의 구조를 print해서 어떻게 뒤 쪽 layer를 디자인 해야할 지 알 수 있습니다.\n",
    "        self.bn_4 = nn.BatchNorm2d(2048, eps=1e-5, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.dropout = nn.Dropout()\n",
    "        self.fc = nn.Linear(2048, dim_feature)\n",
    "        self.bn_5 = nn.BatchNorm1d(dim_feature)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.backbone(x)\n",
    "        out = self.bn_4(out)\n",
    "        out = self.dropout(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "\n",
    "        out = self.fc(out)\n",
    "        out = self.bn_5(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FaceNet\n",
    "\n",
    "위에서 구현한 각 모델의 마지막 FC layer들과 Backbone network를 합쳐서 하나의 얼굴인식모델을 만듭니다.\n",
    "아래 코드의 ??? 부분을 채워주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceNet(nn.Module):\n",
    "    '''\n",
    "    ArcMarginProduct와 FeatureNet-50 을 결합한 ArcFace 모델의 구현\n",
    "    '''\n",
    "    def __init__(self, feature_dim, cls_num, model_type='Cosface'):\n",
    "        super(FaceNet, self).__init__()\n",
    "        self.feature_net = FeatureNet_101(feature_dim)\n",
    "        \n",
    "        if model_type == 'Cosface':\n",
    "            self.classifier = CosMarginProduct(feature_dim, cls_num)\n",
    "        elif model_type == 'Sphereface':\n",
    "            self.classifier = SphereMarginProduct(feature_dim, cls_num)\n",
    "\n",
    "    # 끝까지 Forward 하여 logit을 return\n",
    "    def forward(self, x, label):\n",
    "        out = self.classifier(x, label)\n",
    "        return out\n",
    "    \n",
    "    # Feature를 extract\n",
    "    def extract_feature(self, x):\n",
    "        out = self.feature_net(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두 input 이미지의 유사도를 측정하는데 사용되는 cosine similarity\n",
    "\n",
    "def cos_dist(x1, x2):\n",
    "    return torch.sum(x1 * x2) / (torch.norm(x1) * torch.norm(x2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FaceNet\n",
    "\n",
    "FaceNet을 이용하여 두 input 사이의 similarity를 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SphereFace에서 두 input의 유사도는 0.999979 입니다.\n",
      "CosFace에서 두 input의 유사도는 0.999982 입니다.\n"
     ]
    }
   ],
   "source": [
    "# 두 input입니다.\n",
    "x_1 = torch.randn(1, 3, 128, 128).to(dev)\n",
    "x_2 = torch.randn(1, 3, 128, 128).to(dev)\n",
    "\n",
    "# 각 model을 만듭니다. 이 모델에서 사용하는 feature의 dim은 512고 class는 총 1000개가 있습니다.\n",
    "SphereFaceNet = FaceNet(feature_dim=512, cls_num=1000, model_type='Sphereface').to(dev)\n",
    "CosFaceNet = FaceNet(feature_dim=512, cls_num=1000, model_type='Cosface').to(dev)\n",
    "\n",
    "# test를 위해 model을 test phase로 변경합니다.\n",
    "# 특정 layer는 training과 test 떄 다르게 동작하므로 이 설정은 필수입니다. (ex. dropout, batchnorm ...) \n",
    "SphereFaceNet.eval()\n",
    "CosFaceNet.eval()\n",
    "\n",
    "# x_1, x_2로부터 SphereFace 모델을 이용해 feature를 추출합니다.\n",
    "feature_1 = SphereFaceNet.extract_feature(x_1)\n",
    "feature_2 = SphereFaceNet.extract_feature(x_2)\n",
    "\n",
    "# 두 feature의 유사도를 계산합니다.\n",
    "sim = cos_dist(feature_1, feature_2)\n",
    "print('SphereFace에서 두 input의 유사도는 %f 입니다.' % sim.item())\n",
    "\n",
    "# x_1, x_2로부터 CosFace 모델을 이용해 feature를 추출합니다.\n",
    "feature_1 = CosFaceNet.extract_feature(x_1)\n",
    "feature_2 = CosFaceNet.extract_feature(x_2)\n",
    "\n",
    "# 두 feature의 유사도를 계산합니다.\n",
    "sim = cos_dist(feature_1, feature_2)\n",
    "print('CosFace에서 두 input의 유사도는 %f 입니다.' % sim.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_1 = torch.zeros([1, 1000]).to(dev)\n",
    "label_2 = torch.zeros([1, 1000]).to(dev)\n",
    "label_1[:, 0] = 1.0\n",
    "label_2[:, 1] = 1.0\n",
    "# x_1, x_2로부터 SphereFace 모델을 이용해 feature를 추출합니다.\n",
    "feature_1 = SphereFaceNet.extract_feature(x_1)\n",
    "feature_2 = SphereFaceNet.extract_feature(x_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 4: Index tensor must have same size as output tensor apart from the specified dimension at C:/w/1/s/windows/pytorch/aten/src\\THC/generic/THCTensorScatterGather.cu:324",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-651d2af25f69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mSphereFaceNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\ironm\\tf-nightly\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-d08e50b8a1f4>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, label)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m# 끝까지 Forward 하여 logit을 return\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ironm\\tf-nightly\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-0671d7b6a163>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, label)\u001b[0m\n\u001b[0;32m     34\u001b[0m         '''\n\u001b[0;32m     35\u001b[0m         \u001b[0mone_hot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0mone_hot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mone_hot\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mcos_m\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mone_hot\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mcos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: invalid argument 4: Index tensor must have same size as output tensor apart from the specified dimension at C:/w/1/s/windows/pytorch/aten/src\\THC/generic/THCTensorScatterGather.cu:324"
     ]
    }
   ],
   "source": [
    "SphereFaceNet(feature_1, label_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchvision.utils.save_image(x_2, 'test.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchvision.utils.save_image(x_1, 'test2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
